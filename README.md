<h1 align="center" class="ui-bar-a"> <img alt="awesome-colorful-ai" src="assets/logo.png" width="60"> Colorful Multimodal Research</h1>

<p align="center">
    <a href="https://awesome.re">
        <img alt="awesome", src="https://awesome.re/badge.svg">
    </a>
</p>

Welcome to our meticulously assembled anthology of vibrant multimodal research, encompassing an array of domains including **Vision**, **Audio**, **Agent**, **Robotics**, and **Fundamental Sciences** such as Mathematics. Our collection primarily focuses on the advancements propelled by **large language models (LLMs)**, complemented by an assortment of related collections.

## Table of Contents

- [ðŸ‘€ Vision](#-vision)
  - [Image](#-image)
  - [Video](#-video)
  - [3D](#-3d)
  - [Document](#-documnent)
- [ðŸ‘‚ Audio](#-audio)
- [ðŸ”§ Agent](#-agent)
- [ðŸ¤– Robotic](#-robotic)
- [ðŸ”¬ Science](#-science)
  - [Math](#%EF%B8%8F-ai-for-math)
- [ðŸ™Œ Contributing](#contributing)

## ðŸ‘€ Vision

### ðŸ–¼ Image

Collection of works about Image + LLMs, Diffusion, see [Image](Vision/Image.md) for details

> - Image Understanding
>   - Reading List
>   - Datasets & Benchmarks
> - Image Generation
>   - Reading List
> - Open-source Projects

Related Collections (Understanding)

- [VLM_survey](https://github.com/jingyi0000/VLM_survey) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/jingyi0000/VLM_survey?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/jingyi0000/VLM_survey.svg?style=social&label=Star), This is the repository of "Vision Language Models for Vision Tasks: a Survey", a systematic survey of VLM studies in various visual recognition tasks including image classification, object detection, semantic segmentation, etc.
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/BradyFU/Awesome-Multimodal-Large-Language-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg?style=social&label=Star), A curated list of Multimodal Large Language Models (MLLMs), including datasets, multimodal instruction tuning, multimodal in-context learning, multimodal chain-of-thought, llm-aided visual reasoning, foundation models, and others. This list will be updated in real time.
- [LLM-in-Vision](https://github.com/DirtyHarryLYL/LLM-in-Vision) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/DirtyHarryLYL/LLM-in-Vision?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/DirtyHarryLYL/LLM-in-Vision.svg?style=social&label=Star), Recent LLM (Large Language Models)-based CV and multi-modal works
- [Awesome-Transformer-Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/cmhungsteve/Awesome-Transformer-Attention?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/cmhungsteve/Awesome-Transformer-Attention.svg?style=social&label=Star), This repo contains a comprehensive paper list of Vision Transformer & Attention, including papers, codes, and related websites
- [Multimodal-AND-Large-Language-Models](https://github.com/Yangyi-Chen/Multimodal-AND-Large-Language-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Yangyi-Chen/Multimodal-AND-Large-Language-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/Yangyi-Chen/Multimodal-AND-Large-Language-Models.svg?style=social&label=Star), Paper list about multimodal and large language models, only used to record papers I read in the daily arxiv for personal needs.
- [Efficient_Foundation_Model_Survey](https://github.com/UbiquitousLearning/Efficient_Foundation_Model_Survey) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/UbiquitousLearning/Efficient_Foundation_Model_Survey?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/UbiquitousLearning/Efficient_Foundation_Model_Survey.svg?style=social&label=Star), This repo contains the paper list and figures for A Survey of Resource-efficient LLM and Multimodal Foundation Models.
- [CVinW_Readings](https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Computer-Vision-in-the-Wild/CVinW_Readings?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/Computer-Vision-in-the-Wild/CVinW_Readings.svg?style=social&label=Star), A collection of papers on the topic of Computer Vision in the Wild (CVinW)
- [Awesome-Vision-and-Language](https://github.com/sangminwoo/awesome-vision-and-language) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/sangminwoo/awesome-vision-and-language?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/sangminwoo/awesome-vision-and-language.svg?style=social&label=Star), A curated list of awesome vision and language resources
- [Awesome-Multimodal-Research](https://github.com/Eurus-Holmes/Awesome-Multimodal-Research) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Eurus-Holmes/Awesome-Multimodal-Research?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/Eurus-Holmes/Awesome-Multimodal-Research.svg?style=social&label=Star), This repo is reorganized from Awesome-Multimodal-ML
- [Awesome-Multimodal-ML](https://github.com/pliang279/awesome-multimodal-ml) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/pliang279/awesome-multimodal-ml?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/pliang279/awesome-multimodal-ml.svg?style=social&label=Star), Reading list for research topics in multimodal machine learning
- [Awesome-Referring-Image-Segmentation](https://github.com/MarkMoHR/Awesome-Referring-Image-Segmentation) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/MarkMoHR/Awesome-Referring-Image-Segmentation?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/MarkMoHR/Awesome-Referring-Image-Segmentation.svg?style=social&label=Star), A collection of referring image (video, 3D) segmentation papers and datasets.
- [Awesome-Prompting-on-Vision-Language-Model](https://github.com/JindongGu/Awesome-Prompting-on-Vision-Language-Model) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/JindongGu/Awesome-Prompting-on-Vision-Language-Model?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/JindongGu/Awesome-Prompting-on-Vision-Language-Model.svg?style=social&label=Star), This repo lists relevant papers summarized in our survey paper: A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models.
- [Mamba-in-CV](https://github.com/Yangzhangcst/Mamba-in-CV) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Yangzhangcst/Mamba-in-CV?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/Yangzhangcst/Mamba-in-CV.svg?style=social&label=Star), A paper list of some recent Mamba-based CV works. If you find some ignored papers, please open issues or pull requests.
- [Efficient-Multimodal-LLMs-Survey](https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/lijiannuist/Efficient-Multimodal-LLMs-Survey?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/lijiannuist/Efficient-Multimodal-LLMs-Survey.svg?style=social&label=Star), Efficient Multimodal Large Language Models: A Survey

Related Collections (Evaluation)
- [Awesome-MLLM-Hallucination](https://github.com/showlab/Awesome-MLLM-Hallucination) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/showlab/Awesome-MLLM-Hallucination?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/showlab/Awesome-MLLM-Hallucination.svg?style=social&label=Star), A curated list of resources dedicated to hallucination of multimodal large language models (MLLM)
- [awesome-Large-MultiModal-Hallucination](https://github.com/xieyuquanxx/awesome-Large-MultiModal-Hallucination) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/xieyuquanxx/awesome-Large-MultiModal-Hallucination?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/xieyuquanxx/awesome-Large-MultiModal-Hallucination.svg?style=social&label=Star),

Related Collections (Generation)

- [Awesome-VQVAE](https://github.com/rese1f/Awesome-VQVAE) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/rese1f/Awesome-VQVAE?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/rese1f/Awesome-VQVAE.svg?style=social&label=Star), A collection of resources and papers on Vector Quantized Variational Autoencoder (VQ-VAE) and its application
- [Awesome-Diffusion-Models](https://github.com/heejkoo/Awesome-Diffusion-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/heejkoo/Awesome-Diffusion-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/heejkoo/Awesome-Diffusion-Models.svg?style=social&label=Star), This repository contains a collection of resources and papers on Diffusion Models
- [Awesome-Controllable-Diffusion](https://github.com/atfortes/Awesome-Controllable-Diffusion) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/atfortes/Awesome-Controllable-Diffusion?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/atfortes/Awesome-Controllable-Diffusion.svg?style=social&label=Star), Collection of papers and resources on Controllable Generation using Diffusion Models, including ControlNet, DreamBooth, and others.

Tutorials

- [CVPR2023 Tutorial] [Recent Advances in Vision Foundation Models](https://vlp-tutorial.github.io/)
- [CVPR2022 Tutorial] [Recent Advances in Vision-and-Language Pre-training](https://vlp-tutorial.github.io/)

### ðŸ“º Video

Collection of works about Video-Language Pretraining, Video + LLMs, see [Video](Vision/Video.md) for details

> - Video Understanding
>   - Reading List
>   - Pretraining Tasks
>   - Datasets
>     - Pretraining Corpora
>     - Video Instructions
>   - Benchmarks
>     - Common Downstream Tasks
>     - Advanced Downstream Tasks
>       - Task-Specific Benchmarks
>       - Multifaceted Benchmarks
>   - Metrics
>   - Projects & Tools
> - Video Generation
>   - Reading List
>   - Metrics
>   - Projects

Related Collections (datasets)

- [Awesome-Video-Datasets](https://github.com/xiaobai1217/Awesome-Video-Datasets#Video-and-Language) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/xiaobai1217/Awesome-Video-Datasets?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/xiaobai1217/Awesome-Video-Datasets.svg?style=social&label=Star)

Related Collections (understanding)

- [Awesome-LLMs-for-Video-Understanding](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/yunlong10/Awesome-LLMs-for-Video-Understanding?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/yunlong10/Awesome-LLMs-for-Video-Understanding.svg?style=social&label=Star), Latest Papers, Codes and Datasets on Vid-LLMs.
- [Awesome Long-Term Video Understanding](https://github.com/ttengwang/Awesome_Long_Form_Video_Understanding)![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/ttengwang/Awesome_Long_Form_Video_Understanding?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ttengwang/Awesome_Long_Form_Video_Understanding.svg?style=social&label=Star), Awesome papers & datasets specifically focused on long-term videos.

Related Collections (generation)

- [i2vgen-xl](https://github.com/damo-vilab/i2vgen-xl) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/damo-vilab/i2vgen-xl?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/damo-vilab/i2vgen-xl.svg?style=social&label=Star), VGen is an open-source video synthesis codebase developed by the Tongyi Lab of Alibaba Group, featuring state-of-the-art video generative models.

### ðŸ“· 3D

Collection of works about 3D+LLM, see [3D](Vision/3D.md) for details

> - Reading List

Related Collections

- [awesome-3D-gaussian-splatting](https://github.com/MrNeRF/awesome-3D-gaussian-splatting) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/MrNeRF/awesome-3D-gaussian-splatting?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/MrNeRF/awesome-3D-gaussian-splatting.svg?style=social&label=Star), A curated list of papers and open-source resources focused on 3D Gaussian Splatting, intended to keep pace with the anticipated surge of research in the coming months
- [Awesome-LLM-3D](https://github.com/ActiveVisionLab/Awesome-LLM-3D) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/ActiveVisionLab/Awesome-LLM-3D?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ActiveVisionLab/Awesome-LLM-3D.svg?style=social&label=Star), a curated list of Multi-modal Large Language Model in 3D world Resources
- [Awesome-3D-Vision-and-Language](https://github.com/jianghaojun/Awesome-3D-Vision-and-Language) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/jianghaojun/Awesome-3D-Vision-and-Language?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/jianghaojun/Awesome-3D-Vision-and-Language.svg?style=social&label=Star), A curated list of research papers in 3D visual grounding
- [awesome-scene-understanding](https://github.com/bertjiazheng/awesome-scene-understanding) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/bertjiazheng/awesome-scene-understanding?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/bertjiazheng/awesome-scene-understanding.svg?style=social&label=Star), A list of awesome scene understanding papers.

### ðŸ“° Documnent

Related Collections

- [Awesome Document Understanding](https://github.com/tstanislawek/awesome-document-understanding) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/tstanislawek/awesome-document-understanding?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/tstanislawek/awesome-document-understanding.svg?style=social&label=Star), A curated list of resources for Document Understanding (DU) topic related to Intelligent Document Processing (IDP), which is relative to Robotic Process Automation (RPA) from unstructured data, especially form Visually Rich Documents (VRDs).

## ðŸ‘‚ Audio

Collection of works about audio+LLM, see [Audio](Audio/Audio.md) for details

> - Reading List

Related Collections

- [Audio-AI-Timeline](https://github.com/archinetai/audio-ai-timeline) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/archinetai/audio-ai-timeline?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/archinetai/audio-ai-timeline.svg?style=social&label=Star), Here we will keep track of the latest AI models for waveform based audio generation, starting in 2023!

## ðŸ”§ Agent

Collection of works about agent learning, see [Agent](Agents/Agent.md) for details

> - Reading List
> - Datasets & Benchmarks
> - Projects
> - Applications

Related Collections

- [LLM-Agent-Paper-Digest](https://github.com/XueyangFeng/LLM-Agent-Paper-Digest) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/XueyangFeng/LLM-Agent-Paper-Digest?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/XueyangFeng/LLM-Agent-Paper-Digest.svg?style=social&label=Star), For benefiting the research community and promoting LLM-powered agent direction, we organize papers related to LLM-powered agent that published on top conferences recently
- [LLMAgentPapers](https://github.com/zjunlp/LLMAgentPapers) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/zjunlp/LLMAgentPapers?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/zjunlp/LLMAgentPapers.svg?style=social&label=Star), Must-read Papers on Large Language Model Agents.
- [LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/WooooDyy/LLM-Agent-Paper-List?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/WooooDyy/LLM-Agent-Paper-List.svg?style=social&label=Star), In this repository, we provide a systematic and comprehensive survey on LLM-based agents, and list some must-read papers.
- [XLang Paper Reading](https://github.com/xlang-ai/xlang-paper-reading) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/xlang-ai/xlang-paper-reading?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/xlang-ai/xlang-paper-reading.svg?style=social&label=Star), Paper collection on building and evaluating language model agents via executable language grounding
- [Awesome-LLMOps](https://github.com/tensorchord/Awesome-LLMOps) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/tensorchord/Awesome-LLMOps?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/tensorchord/Awesome-LLMOps.svg?style=social&label=Star), An awesome & curated list of best LLMOps tools for developers
- [Awesome LLM-Powered Agent](https://github.com/hyp1231/awesome-llm-powered-agent) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/hyp1231/awesome-llm-powered-agent?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/hyp1231/awesome-llm-powered-agent.svg?style=social&label=Star), Awesome things about LLM-powered agents. Papers / Repos / Blogs / ...
- [Awesome LMs with Tools](https://github.com/zorazrw/awesome-tool-llm) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/zorazrw/awesome-tool-llm?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/zorazrw/awesome-tool-llm.svg?style=social&label=Star), Language models (LMs) are powerful yet mostly for text-generation tasks. Tools have substantially enhanced their performance for tasks that require complex skills.
- [ToolLearningPapers](https://github.com/thunlp/ToolLearningPapers) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/thunlp/ToolLearningPapers?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/thunlp/ToolLearningPapers.svg?style=social&label=Star), Must-read papers on tool learning with foundation models
- [Awesome-ALM](https://github.com/pbhu1024/awesome-augmented-language-model) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/pbhu1024/awesome-augmented-language-model?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/pbhu1024/awesome-augmented-language-model.svg?style=social&label=Star), This repo collect research papers about leveraging the capabilities of language models, which can be a good reference for building upper-layer applications
- [LLM-powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/), Lil'Log, Overview: panning, memory, tool use
- [World Model Papers](https://github.com/Timothyxxx/WorldModelPapers), ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Timothyxxx/WorldModelPapers?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/Timothyxxx/WorldModelPapers.svg?style=social&label=Star), Paper collections of the continuous effort start from World Models

## ðŸ¤– Robotic

Collection of works about robotics+LLM, see [Robotic](Robotic/Robotic.md) for details

> - Reading List

Related Collections (Robotics)

- [Awesome-Robotics-Foundation-Models](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/robotics-survey/Awesome-Robotics-Foundation-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/robotics-survey/Awesome-Robotics-Foundation-Models.svg?style=social&label=Star), This is the partner repository for the survey paper "Foundation Models in Robotics: Applications, Challenges, and the Future". The authors hope this repository can act as a quick reference for roboticists who wish to read the relevant papers and implement the associated methods.
- [Awesome-LLM-Robotics](https://github.com/GT-RIPL/Awesome-LLM-Robotics) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/GT-RIPL/Awesome-LLM-Robotics?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/GT-RIPL/Awesome-LLM-Robotics.svg?style=social&label=Star), This repo contains a curative list of papers using Large Language/Multi-Modal Models for Robotics/RL
- [Simulately](https://github.com/geng-haoran/Simulately) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/geng-haoran/Simulately?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/geng-haoran/Simulately.svg?style=social&label=Star), a website where we gather useful information of physics simulator for cutting-edge robot learning research. It is still under active development, so stay tuned!
- [Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation](https://github.com/zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation.svg?style=social&label=Star), Temporal Action Detection & Weakly Supervised & Semi Supervised Temporal Action Detection & Temporal Action Proposal Generation & Open-Vocabulary Temporal Action Detection.
- [Awesome-TimeSeries-SpatioTemporal-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM.svg?style=social&label=Star), A professionally curated list of **Large (Language) Models and Foundation Models (LLM, LM, FM) for Temporal Data (Time Series, Spatio-temporal, and Event Data)** with awesome resources (paper, code, data, etc.), which aims to comprehensively and systematically summarize the recent advances to the best of our knowledge.
- [PromptCraft-Robotics](https://github.com/microsoft/PromptCraft-Robotics) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/microsoft/PromptCraft-Robotics?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/microsoft/PromptCraft-Robotics.svg?style=social&label=Star), The PromptCraft-Robotics repository serves as a community for people to test and share interesting prompting examples for large language models (LLMs) within the robotics domain
- [Awesome-Robotics](https://github.com/ahundt/awesome-robotics) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/ahundt/awesome-robotics?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ahundt/awesome-robotics.svg?style=social&label=Star), A curated list of awesome links and software libraries that are useful for robots

Related Collections (embodied)

- [Awesome-Embodied-AI](https://github.com/haoranD/Awesome-Embodied-AI) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/haoranD/Awesome-Embodied-AI?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/haoranD/Awesome-Embodied-AI.svg?style=social&label=Star), A curated list of awesome papers on Embodied AI and related research/industry-driven resources
- [awesome-embodied-vision](https://github.com/ChanganVR/awesome-embodied-vision) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/ChanganVR/awesome-embodied-vision?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ChanganVR/awesome-embodied-vision.svg?style=social&label=Star), Reading list for research topics in embodied vision

Related Collections (autonomous driving)

- [Awesome-LLM4AD](https://github.com/Thinklab-SJTU/Awesome-LLM4AD) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Thinklab-SJTU/Awesome-LLM4AD?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ChangThinklab-SJTUanVR/Awesome-LLM4AD.svg?style=social&label=Star), A curated list of awesome LLM for Autonomous Driving resources (continually updated)

## ðŸ”¬ Science

### â™¾ï¸ AI for Math

Collection of works about Mathematics + LLMs, see [AI4Math](AI4Science/AI4Math.md) for details

> - Reading List

Related Collections

- [Awesome-Scientific-Language-Models](https://github.com/yuzhimanhua/Awesome-Scientific-Language-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/yuzhimanhua/Awesome-Scientific-Language-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/yuzhimanhua/Awesome-Scientific-Language-Models.svg?style=social&label=Star), A curated list of pre-trained language models in scientific domains (e.g., mathematics, physics, chemistry, biology, medicine, materials science, and geoscience), covering different model sizes (from <100M to 70B parameters) and modalities (e.g., language, vision, molecule, protein, graph, and table)

## Contributing

Please freely create a [pull request](https://github.com/patrick-tssn/Awesome-Colorful-LLM/pulls) or drop me an email: [flagwyx@gmail.com](flagwyx@gmail.com)
